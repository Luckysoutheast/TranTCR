{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5bf118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font',family='Times New Roman')\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.size'] = 12\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "from scipy import interp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from tqdm import tqdm, trange\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, auc\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a166e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from Bio.Align import substitution_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658a55f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: [seq_len, batch_size, d_model]\n",
    "        '''\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    '''\n",
    "    seq_q: [batch_size, seq_len]\n",
    "    seq_k: [batch_size, seq_len]\n",
    "    seq_len could be src_len or it could be tgt_len\n",
    "    seq_len in seq_q and seq_len in seq_k maybe not equal\n",
    "    '''\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # [batch_size, 1, len_k], False is masked\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # [batch_size, len_q, len_k]\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        '''\n",
    "        Q: [batch_size, n_heads, len_q, d_k]\n",
    "        K: [batch_size, n_heads, len_k, d_k]\n",
    "        V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "        attn_mask: [batch_size, n_heads, seq_len, seq_len]\n",
    "        '''\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size, n_heads, len_q, len_k]\n",
    "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is True.\n",
    "#         attn = scores\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V) # [batch_size, n_heads, len_q, d_v]\n",
    "        return context, attn\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "        self.fc = nn.Linear(n_heads * d_v, d_model, bias=False)\n",
    "    def forward(self, input_Q, input_K, input_V, attn_mask):\n",
    "        '''\n",
    "        input_Q: [batch_size, len_q, d_model]\n",
    "        input_K: [batch_size, len_k, d_model]\n",
    "        input_V: [batch_size, len_v(=len_k), d_model]\n",
    "        attn_mask: [batch_size, seq_len, seq_len]\n",
    "        '''\n",
    "        residual, batch_size = input_Q, input_Q.size(0)\n",
    "        # (B, S, D) -proj-> (B, S, D_new) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # Q: [batch_size, n_heads, len_q, d_k]\n",
    "        K = self.W_K(input_K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # K: [batch_size, n_heads, len_k, d_k]\n",
    "        V = self.W_V(input_V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  # V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask : [batch_size, n_heads, seq_len, seq_len]\n",
    "\n",
    "        # context: [batch_size, n_heads, len_q, d_v], attn: [batch_size, n_heads, len_q, len_k]\n",
    "        context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)\n",
    "        context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v) # context: [batch_size, len_q, n_heads * d_v]\n",
    "        output = self.fc(context) # [batch_size, len_q, d_model]\n",
    "        return nn.LayerNorm(d_model).to(device)(output + residual), attn\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model, bias=False)\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        inputs: [batch_size, seq_len, d_model]\n",
    "        '''\n",
    "        residual = inputs\n",
    "        output = self.fc(inputs)\n",
    "        return nn.LayerNorm(d_model).to(device)(output + residual) # [batch_size, seq_len, d_model]\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len, d_model]\n",
    "        enc_self_attn_mask: [batch_size, src_len, src_len]\n",
    "        '''\n",
    "        # enc_outputs: [batch_size, src_len, d_model], attn: [batch_size, n_heads, src_len, src_len]\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size, src_len, d_model]\n",
    "        return enc_outputs, attn\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.src_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, enc_inputs):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        '''\n",
    "        enc_outputs = self.src_emb(enc_inputs) # [batch_size, src_len, d_model]\n",
    "        enc_outputs = self.pos_emb(enc_outputs.transpose(0, 1)).transpose(0, 1) # [batch_size, src_len, d_model]\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs) # [batch_size, src_len, src_len]\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            # enc_outputs: [batch_size, src_len, d_model], enc_self_attn: [batch_size, n_heads, src_len, src_len]\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        return enc_outputs, enc_self_attns\n",
    "\n",
    "\n",
    "# ### Decoder\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, dec_inputs, dec_self_attn_mask): # dec_inputs = enc_outputs\n",
    "        '''\n",
    "        dec_inputs: [batch_size, tgt_len, d_model]\n",
    "        enc_outputs: [batch_size, src_len, d_model]\n",
    "        dec_self_attn_mask: [batch_size, tgt_len, tgt_len]\n",
    "        '''\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n",
    "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "        dec_outputs = self.pos_ffn(dec_outputs) # [batch_size, tgt_len, d_model]\n",
    "        return dec_outputs, dec_self_attn\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "#         self.tgt_emb = nn.Embedding(d_model * 2, d_model)\n",
    "        self.use_cuda = use_cuda\n",
    "        device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
    "        self.tgt_len = tgt_len\n",
    "        \n",
    "    def forward(self, dec_inputs): # dec_inputs = enc_outputs (batch_size, peptide_hla_maxlen_sum, d_model)\n",
    "        '''\n",
    "        dec_inputs: [batch_size, tgt_len]\n",
    "        enc_intpus: [batch_size, src_len]\n",
    "        enc_outputs: [batsh_size, src_len, d_model]\n",
    "        '''\n",
    "#         dec_outputs = self.tgt_emb(dec_inputs) # [batch_size, tgt_len, d_model]\n",
    "        dec_outputs = self.pos_emb(dec_inputs.transpose(0, 1)).transpose(0, 1).to(device) # [batch_size, tgt_len, d_model]\n",
    "#         dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs).cuda() # [batch_size, tgt_len, tgt_len]\n",
    "        dec_self_attn_pad_mask = torch.LongTensor(np.zeros((dec_inputs.shape[0], tgt_len, tgt_len))).bool().to(device)\n",
    " \n",
    "        dec_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [batch_size, h_heads, tgt_len, src_len]\n",
    "            dec_outputs, dec_self_attn = layer(dec_outputs, dec_self_attn_pad_mask)\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            \n",
    "        return dec_outputs, dec_self_attns\n",
    "\n",
    "\n",
    "# ### Transformer\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self.pep_encoder = Encoder().to(device)\n",
    "        self.hla_encoder = Encoder().to(device)\n",
    "        self.decoder = Decoder().to(device)\n",
    "        self.tgt_len = tgt_len\n",
    "        self.projection = nn.Sequential(\n",
    "                                        nn.Linear(tgt_len * d_model, 256),\n",
    "                                        nn.ReLU(True),\n",
    "\n",
    "                                        nn.BatchNorm1d(256),\n",
    "                                        nn.Linear(256, 64),\n",
    "                                        nn.ReLU(True),\n",
    "\n",
    "                                        #output layer\n",
    "                                        nn.Linear(64, 2)\n",
    "                                        ).to(device)\n",
    "        \n",
    "    def forward(self, hla_inputs,pep_inputs):\n",
    "        '''\n",
    "        pep_inputs: [batch_size, pep_len]\n",
    "        hla_inputs: [batch_size, hla_len]\n",
    "        '''\n",
    "        # tensor to store decoder outputs\n",
    "        # outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
    "        \n",
    "        # enc_outputs: [batch_size, src_len, d_model], enc_self_attns: [n_layers, batch_size, n_heads, src_len, src_len]\n",
    "        hla_enc_outputs, hla_enc_self_attns = self.hla_encoder(hla_inputs)\n",
    "        pep_enc_outputs, pep_enc_self_attns = self.pep_encoder(pep_inputs)\n",
    "        \n",
    "#         print(hla_enc_outputs)\n",
    "        enc_outputs = torch.cat((hla_enc_outputs,pep_enc_outputs), 1) # concat pep & hla embedding\n",
    "        ## reverse ##\n",
    "#         enc_outputs = pep_enc_outputs*hla_enc_outputs\n",
    "        \n",
    "        ## end ##\n",
    "        # dec_outpus: [batch_size, tgt_len, d_model], dec_self_attns: [n_layers, batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [n_layers, batch_size, tgt_len, src_len]\n",
    "        dec_outputs, dec_self_attns = self.decoder(enc_outputs)\n",
    "        dec_outputs = dec_outputs.view(dec_outputs.shape[0], -1) # Flatten [batch_size, tgt_len * d_model]\n",
    "        dec_logits = self.projection(dec_outputs) # dec_logits: [batch_size, tgt_len, tgt_vocab_size]\n",
    "\n",
    "        return dec_logits.view(-1, dec_logits.size(-1)), pep_enc_self_attns, hla_enc_self_attns, dec_self_attns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6902b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pep_max_len = 12 # peptide; enc_input max sequence length\n",
    "hla_max_len = 20 # hla; dec_input(=dec_output) max sequence length\n",
    "tgt_len = pep_max_len + hla_max_len\n",
    "pep_max_len, hla_max_len\n",
    "\n",
    "# vocab = {'C': 1, 'W': 2, 'V': 3, 'A': 4, 'H': 5, 'T': 6, 'E': 7, 'K': 8, 'N': 9, 'P': 10, 'I': 11, 'L': 12, 'S': 13, 'D': 14, 'G': 15, 'Q': 16, 'R': 17, 'Y': 18, 'F': 19, 'M': 20, '-': 0}\n",
    "vocab_size = 21\n",
    "\n",
    "d_model=64 # Embedding Size\n",
    "d_ff = 256 # FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_layers = 1  # number of Encoder of Decoder Layer\n",
    "\n",
    "\n",
    "n_heads = 5\n",
    "\n",
    "batch_size = 1024\n",
    "# batch_size = 5000\n",
    "epochs = 150\n",
    "threshold = 0.5\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a4fd541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def performances(y_true, y_pred, y_prob,output_file='None', print_ = True):\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels = [0, 1]).ravel().tolist()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    try:\n",
    "        mcc = ((tp*tn) - (fn*fp)) / np.sqrt(np.float((tp+fn)*(tn+fp)*(tp+fp)*(tn+fn)))\n",
    "    except:\n",
    "        print('MCC Error: ', (tp+fn)*(tn+fp)*(tp+fp)*(tn+fn))\n",
    "        mcc = np.nan\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    \n",
    "    try:\n",
    "        recall = tp / (tp+fn)\n",
    "    except:\n",
    "        recall = np.nan\n",
    "        \n",
    "    try:\n",
    "        precision = tp / (tp+fp)\n",
    "    except:\n",
    "        precision = np.nan\n",
    "        \n",
    "    try: \n",
    "        f1 = 2*precision*recall / (precision+recall)\n",
    "    except:\n",
    "        f1 = np.nan\n",
    "        \n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    prec, reca, _ = precision_recall_curve(y_true, y_prob)\n",
    "    aupr = auc(reca, prec)\n",
    "    \n",
    "    if print_:\n",
    "        print('tn = {}, fp = {}, fn = {}, tp = {}'.format(tn, fp, fn, tp))\n",
    "        print('y_pred: 0 = {} | 1 = {}'.format(Counter(y_pred)[0], Counter(y_pred)[1]))\n",
    "        print('y_true: 0 = {} | 1 = {}'.format(Counter(y_true)[0], Counter(y_true)[1]))\n",
    "        print('auc={:.4f}|sensitivity={:.4f}|specificity={:.4f}|acc={:.4f}|mcc={:.4f}'.format(roc_auc, sensitivity, specificity, accuracy, mcc))\n",
    "        print('precision={:.4f}|recall={:.4f}|f1={:.4f}|aupr={:.4f}'.format(precision, recall, f1, aupr))\n",
    "    if output_file is not None:\n",
    "        with open(output_file, 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            if csvfile.tell() == 0:\n",
    "                writer.writerow(['tn', 'fp', 'fn', 'tp', 'y_pred_0', 'y_pred_1', 'y_true_0', 'y_true_1', 'auc', 'sensitivity', 'specificity', 'accuracy', 'mcc', 'precision', 'recall', 'f1', 'aupr'])\n",
    "            writer.writerow([tn, fp, fn, tp, Counter(y_pred)[0], Counter(y_pred)[1], Counter(y_true)[0], Counter(y_true)[1], roc_auc, sensitivity, specificity, accuracy, mcc, precision, recall, f1, aupr])\n",
    "    return (roc_auc, accuracy, mcc, f1, sensitivity, specificity, precision, recall, aupr)\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "def transfer(y_prob, threshold = 0.5):\n",
    "    # return np.array([[0, 1][x > threshold] for x in y_prob])\n",
    "    y_prob = np.array(y_prob)\n",
    "    return np.where(y_prob > threshold, 1, 0)\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "f_mean = lambda l: sum(l)/len(l)\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "def performances_to_pd(performances_list):\n",
    "    metrics_name = ['roc_auc', 'accuracy', 'mcc', 'f1', 'sensitivity', 'specificity', 'precision', 'recall', 'aupr']\n",
    "\n",
    "    performances_pd = pd.DataFrame(performances_list, columns = metrics_name)\n",
    "    performances_pd.loc['mean'] = performances_pd.mean(axis = 0)\n",
    "    performances_pd.loc['std'] = performances_pd.std(axis = 0)\n",
    "    \n",
    "    return performances_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a4e607",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(model, train_loader, fold, epoch, epochs, use_cuda = True):\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    time_train_ep = 0\n",
    "    model.train()\n",
    "    y_true_train_list, y_prob_train_list = [], []\n",
    "    loss_train_list, dec_attns_train_list = [], []\n",
    "    for train_pep_inputs, train_hla_inputs, train_labels in tqdm(train_loader):\n",
    "        '''\n",
    "        pep_inputs: [batch_size, pep_len]\n",
    "        hla_inputs: [batch_size, hla_len]\n",
    "        train_outputs: [batch_size, 2]\n",
    "        '''\n",
    "        train_pep_inputs, train_hla_inputs, train_labels = train_pep_inputs.to(device), train_hla_inputs.to(device), train_labels.to(device)\n",
    "#         print(train_pep_inputs.shape,train_hla_inputs.shape)\n",
    "        t1 = time.time()\n",
    "        train_outputs, _, _, train_dec_self_attns = model(train_hla_inputs, train_pep_inputs)\n",
    "        train_loss = criterion(train_outputs, train_labels)\n",
    "        time_train_ep += time.time() - t1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_true_train = train_labels.cpu().numpy()\n",
    "        y_prob_train = nn.Softmax(dim = 1)(train_outputs)[:, 1].cpu().detach().numpy()\n",
    "        \n",
    "        y_true_train_list.extend(y_true_train)\n",
    "        y_prob_train_list.extend(y_prob_train)\n",
    "        loss_train_list.append(train_loss)\n",
    "#         dec_attns_train_list.append(train_dec_self_attns)\n",
    "        \n",
    "    y_pred_train_list = transfer(y_prob_train_list, threshold)\n",
    "    ys_train = (y_true_train_list, y_pred_train_list, y_prob_train_list)\n",
    "    \n",
    "    print('Fold-{}****Train (Ep avg): Epoch-{}/{} | Loss = {:.4f} | Time = {:.4f} sec'.format(fold, epoch, epochs, f_mean(loss_train_list), time_train_ep))\n",
    "    metrics_train = performances(y_true_train_list, y_pred_train_list, y_prob_train_list, print_ = True)\n",
    "    \n",
    "    return ys_train, loss_train_list, metrics_train, time_train_ep#, dec_attns_train_list\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "def eval_step(model, val_loader, fold, epoch, epochs, dir_head, use_cuda = True):\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "#     torch.manual_seed(19961231)\n",
    "#     torch.cuda.manual_seed(19961231)\n",
    "    with torch.no_grad():\n",
    "        loss_val_list, dec_attns_val_list = [], []\n",
    "        y_true_val_list, y_prob_val_list = [], []\n",
    "        for val_pep_inputs, val_hla_inputs, val_labels in tqdm(val_loader):\n",
    "            val_pep_inputs, val_hla_inputs, val_labels = val_pep_inputs.to(device), val_hla_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs, _, _, val_dec_self_attns = model(val_hla_inputs,val_pep_inputs)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "            y_true_val = val_labels.cpu().numpy()\n",
    "            y_prob_val = nn.Softmax(dim = 1)(val_outputs)[:, 1].cpu().detach().numpy()\n",
    "\n",
    "            y_true_val_list.extend(y_true_val)\n",
    "            y_prob_val_list.extend(y_prob_val)\n",
    "            loss_val_list.append(val_loss)\n",
    "#             dec_attns_val_list.append(val_dec_self_attns)\n",
    "            \n",
    "        y_pred_val_list = transfer(y_prob_val_list, threshold)\n",
    "        ys_val = (y_true_val_list, y_pred_val_list, y_prob_val_list)\n",
    "        \n",
    "        print('Fold-{} ****Test  Epoch-{}/{}: Loss = {:.6f}'.format(fold, epoch, epochs, f_mean(loss_val_list)))\n",
    "        dir_name = str(dir_head)+'_Fold-{}.csv'.format(fold)\n",
    "        metrics_val = performances(y_true_val_list, y_pred_val_list, y_prob_val_list, dir_name,True)\n",
    "    return ys_val, loss_val_list, metrics_val#, dec_attns_val_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a372af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data(data):\n",
    "#     labels = []\n",
    "    cdr3 = data['CDR3b'].values\n",
    "    epitope = data['peptide'].values\n",
    "    labels = data['binder'].values\n",
    "    mat = Tokenizer() \n",
    "    hla_inputs = encode_cdr3(cdr3, mat)\n",
    "#     print(hla_inputs)\n",
    "    pep_inputs = encode_epi(epitope, mat)\n",
    "#     epi_encoder = PretrainedEncoder(mat)\n",
    "#     pep_inputs, epi_vec = epi_encoder.encode_pretrained_epi(epitope)\n",
    "\n",
    "#     labels.append(label)\n",
    "    return torch.LongTensor(pep_inputs), torch.LongTensor(hla_inputs), torch.LongTensor(labels)\n",
    "\n",
    "class MyDataSet(Data.Dataset):\n",
    "    def __init__(self, pep_inputs, hla_inputs,labels):\n",
    "        super(MyDataSet, self).__init__()\n",
    "        self.pep_inputs = pep_inputs\n",
    "        self.hla_inputs = hla_inputs\n",
    "        self.labels = labels\n",
    "        \n",
    "\n",
    "    def __len__(self): # 样本数\n",
    "        return self.pep_inputs.shape[0] # 改成hla_inputs也可以哦！\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         return self.pep_inputs[idx], self.hla_inputs[idx], self.labels[idx],self.pep_lens[idx]\n",
    "        return self.pep_inputs[idx],self.hla_inputs[idx], self.labels[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc82d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025cbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "176f393f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Bio.Align import substitution_matrices\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "\n",
    "def GetBlosumMat(residues_list):\n",
    "    n_residues = len(residues_list)  # the number of amino acids _ 'X'\n",
    "    blosum62_mat = np.zeros([n_residues, n_residues])  # plus 1 for gap\n",
    "    bl_dict = substitution_matrices.load('BLOSUM62')\n",
    "    for pair, score in bl_dict.items():\n",
    "        if (pair[0] not in residues_list) or (pair[1] not in residues_list):  # special residues not considered here\n",
    "            continue\n",
    "        idx_pair0 = residues_list.index(pair[0])  # index of residues\n",
    "        idx_pair1 = residues_list.index(pair[1])\n",
    "        blosum62_mat[idx_pair0, idx_pair1] = score\n",
    "        blosum62_mat[idx_pair1, idx_pair0] = score\n",
    "    return blosum62_mat\n",
    "\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self,):\n",
    "        self.res_all = ['G', 'A', 'V', 'L', 'I', 'F', 'W', 'Y', 'D', 'N',\n",
    "                     'E', 'K', 'Q', 'M', 'S', 'T', 'C', 'P', 'H', 'R'] #+ ['X'] #BJZOU\n",
    "        self.tokens = ['-'] + self.res_all # '-' for padding encoding\n",
    "\n",
    "    def tokenize(self, index): # int 2 str\n",
    "        return self.tokens[index]\n",
    "\n",
    "    def id(self, token): # str 2 int\n",
    "        try:\n",
    "            return self.tokens.index(token.upper())\n",
    "        except ValueError:\n",
    "            print('Error letter in the sequences:', token)\n",
    "            if str.isalpha(token):\n",
    "                return self.tokens.index('X')\n",
    "\n",
    "    def tokenize_list(self, seq):\n",
    "        return [self.tokenize(i) for i in seq]\n",
    "\n",
    "    def id_list(self, seq):\n",
    "        return [self.id(s) for s in seq]\n",
    "\n",
    "    def embedding_mat(self):\n",
    "        blosum62 = GetBlosumMat(self.res_all)\n",
    "        mat = np.eye(len(self.tokens))\n",
    "        mat[1:len(self.res_all) + 1, 1:len(self.res_all) + 1] = blosum62\n",
    "        return mat\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "\n",
    "def encoding_epi(seqs, max_len=12):\n",
    "    encoding = np.zeros([len(seqs), max_len], dtype='long')\n",
    "    for i, seq in tqdm(enumerate(seqs), desc='Encoding epi seqs', total=len(seqs)):\n",
    "        len_seq = len(seq)\n",
    "        if len_seq == 8:\n",
    "            encoding[i, 2:len_seq+2] = tokenizer.id_list(seq)\n",
    "        elif (len_seq == 9) or (len_seq == 10):\n",
    "            encoding[i, 1:len_seq+1] = tokenizer.id_list(seq)\n",
    "        else:\n",
    "            encoding[i, :len_seq] = tokenizer.id_list(seq)\n",
    "    return encoding\n",
    "\n",
    "def encoding_cdr3(seqs, max_len=20):\n",
    "    encoding = np.zeros([len(seqs), max_len], dtype='long')\n",
    "    for i, seq in tqdm(enumerate(seqs), desc='Encoding cdr3s', total=len(seqs)):\n",
    "        len_seq = len(seq)\n",
    "        i_start =  max_len // 2 - len_seq // 2\n",
    "        encoding[i, i_start:i_start+len_seq] = tokenizer.id_list(seq)\n",
    "    return encoding\n",
    "\n",
    "def encoding_cdr3_single(seq, max_len=20):\n",
    "    encoding = np.zeros(max_len, dtype='long')\n",
    "    len_seq = len(seq)\n",
    "    i_start =  max_len // 2 - len_seq // 2\n",
    "    encoding[i_start:i_start+len_seq] = tokenizer.id_list(seq)\n",
    "    return encoding\n",
    "\n",
    "def encoding_epi_single(seq, max_len=12):\n",
    "    encoding = np.zeros(max_len, dtype='long')\n",
    "    len_seq = len(seq)\n",
    "    if len_seq == 8:\n",
    "        encoding[2:len_seq+2] = tokenizer.id_list(seq)\n",
    "    elif (len_seq == 9) or (len_seq == 10):\n",
    "        encoding[1:len_seq+1] = tokenizer.id_list(seq)\n",
    "    else:\n",
    "        encoding[:len_seq] = tokenizer.id_list(seq)\n",
    "    return encoding\n",
    "\n",
    "\n",
    "def encoding_dist_mat(mat_list, max_cdr3=20, max_epi=12):\n",
    "    encoding = np.zeros([len(mat_list), max_cdr3, max_epi], dtype='float32')\n",
    "    masking = np.zeros([len(mat_list), max_cdr3, max_epi], dtype='bool')\n",
    "    for i, mat in tqdm(enumerate(mat_list), desc='Encoding dist mat', total=len(mat_list)):\n",
    "        len_cdr3, len_epi = mat.shape\n",
    "        i_start_cdr3 = max_cdr3 // 2 - len_cdr3 // 2\n",
    "        if len_epi == 8:\n",
    "            i_start_epi = 2\n",
    "        elif (len_epi == 9) or (len_epi == 10):\n",
    "            i_start_epi = 1\n",
    "        else:\n",
    "            i_start_epi = 0\n",
    "        encoding[i, i_start_cdr3:i_start_cdr3+len_cdr3, i_start_epi:i_start_epi+len_epi] = mat\n",
    "        masking[i, i_start_cdr3:i_start_cdr3+len_cdr3, i_start_epi:i_start_epi+len_epi] = True\n",
    "    return encoding, masking\n",
    "\n",
    "\n",
    "def decoding_one_mat(mat, len_cdr3, len_epi):\n",
    "    decoding = np.zeros([len_cdr3, len_epi] + list(mat.shape[2:]), dtype=mat.dtype)\n",
    "    i_start_cdr3 = 10 - len_cdr3 // 2\n",
    "    if len_epi == 8:\n",
    "        i_start_epi = 2\n",
    "    elif (len_epi == 9) or (len_epi == 10):\n",
    "        i_start_epi = 1\n",
    "    else:\n",
    "        i_start_epi = 0\n",
    "    decoding = mat[i_start_cdr3:i_start_cdr3+len_cdr3, i_start_epi:i_start_epi+len_epi] \n",
    "    return decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afc8d9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Bio.Align import substitution_matrices\n",
    "def GetBlosumMat(residues_list):\n",
    "    n_residues = len(residues_list)  # the number of amino acids _ 'X'\n",
    "    blosum62_mat = np.zeros([n_residues, n_residues])  # plus 1 for gap\n",
    "    bl_dict = substitution_matrices.load('BLOSUM62')\n",
    "    for pair, score in bl_dict.items():\n",
    "        if (pair[0] not in residues_list) or (pair[1] not in residues_list):  # special residues not considered here\n",
    "            continue\n",
    "        idx_pair0 = residues_list.index(pair[0])  # index of residues\n",
    "        idx_pair1 = residues_list.index(pair[1])\n",
    "        blosum62_mat[idx_pair0, idx_pair1] = score\n",
    "        blosum62_mat[idx_pair1, idx_pair0] = score\n",
    "    return blosum62_mat\n",
    "class Tokenizer:\n",
    "    def __init__(self,):\n",
    "        self.res_all = ['G', 'A', 'V', 'L', 'I', 'F', 'W', 'Y', 'D', 'N',\n",
    "                     'E', 'K', 'Q', 'M', 'S', 'T', 'C', 'P', 'H', 'R'] #+ ['X'] #BJZOU\n",
    "        self.tokens = ['-'] + self.res_all # '-' for padding encoding\n",
    "\n",
    "    def tokenize(self, index): # int 2 str\n",
    "        return self.tokens[index]\n",
    "\n",
    "    def id(self, token): # str 2 int\n",
    "        try:\n",
    "            return self.tokens.index(token.upper())\n",
    "        except ValueError:\n",
    "            print('Error letter in the sequences:', token)\n",
    "            if str.isalpha(token):\n",
    "                return self.tokens.index('X')\n",
    "\n",
    "    def tokenize_list(self, seq):\n",
    "        return [self.tokenize(i) for i in seq]\n",
    "\n",
    "    def id_list(self, seq):\n",
    "        return [self.id(s) for s in seq]\n",
    "\n",
    "    def embedding_mat(self):\n",
    "        blosum62 = GetBlosumMat(self.res_all)\n",
    "        mat = np.eye(len(self.tokens))\n",
    "        mat[1:len(self.res_all) + 1, 1:len(self.res_all) + 1] = blosum62\n",
    "        return mat\n",
    "def encode_cdr3(cdr3, tokenizer):\n",
    "    len_cdr3 = [len(s) for s in cdr3]\n",
    "    max_len_cdr3 = np.max(len_cdr3)\n",
    "    assert max_len_cdr3 <= 20, 'The cdr3 length must <= 20'\n",
    "    max_len_cdr3 = 20\n",
    "    \n",
    "    seqs_al = get_numbering(cdr3)\n",
    "    print(seqs_al)\n",
    "    num_samples = len(seqs_al)\n",
    "\n",
    "    # encoding\n",
    "    encoding_cdr3 = np.zeros([num_samples, max_len_cdr3], dtype='int32')\n",
    "    for i, seq in enumerate(seqs_al):\n",
    "#         print(seq)\n",
    "        encoding_cdr3[i, ] = tokenizer.id_list(seq)\n",
    "    return encoding_cdr3\n",
    "def encode_epi(epi, tokenizer):\n",
    "    tokenizer = Tokenizer()\n",
    "    encoding_epi = np.zeros([len(epi),12], dtype='int32')\n",
    "    for i, seq in enumerate(epi):\n",
    "        len_epi = len(seq)\n",
    "        \n",
    "        if len_epi == 8:\n",
    "        \n",
    "            encoding_epi[i,2:len_epi+2] = tokenizer.id_list(seq)\n",
    "        elif (len_epi == 9) or (len_epi == 10) or (len_epi ==11):\n",
    "            \n",
    "            encoding_epi[i,1:len_epi+1] = tokenizer.id_list(seq)\n",
    "        else:\n",
    "            \n",
    "            encoding_epi[i,:len_epi] = tokenizer.id_list(seq)\n",
    "    print(encoding_epi)\n",
    "    return encoding_epi\n",
    "def get_numbering(seqs, ):\n",
    "    \"\"\"\n",
    "    get the IMGT numbering of CDR3 with ANARCI tool\n",
    "    \"\"\"\n",
    "    template = ['GVTQTPKFQVLKTGQSMTLQCAQDMNHEYMSWYRQDPGMGLRLIHYSVGAGTTDQGEVPNGYNVSRSTIEDFPLRLLSAAPSQTSVYF', 'GEGSRLTVL']\n",
    "    # # save fake tcr file\n",
    "    save_path = 'tmp_faketcr.fasta'\n",
    "    id_list = []\n",
    "    seqs_uni = np.unique(seqs)\n",
    "    with open(save_path, 'w+') as f:\n",
    "        for i, seq in enumerate(seqs_uni):\n",
    "            f.write('>'+str(i)+'\\n')\n",
    "            id_list.append(i)\n",
    "            total_seq = ''.join([template[0], seq ,template[1]])\n",
    "            f.write(str(total_seq))\n",
    "            f.write('\\n')\n",
    "    print('Save fasta file to '+save_path + '\\n Aligning...')\n",
    "    df_seqs = pd.DataFrame(list(zip(id_list, seqs_uni)), columns=['Id', 'cdr3'])\n",
    "    \n",
    "    # # using ANARCI to get numbering file\n",
    "\n",
    "   # this environment name should be the same as the one you install anarci\n",
    "    !ANARCI -i ./tmp_faketcr.fasta  -o tmp_align --csv -p 24\n",
    "#     res = os.system(cmd)\n",
    "    \n",
    "    # # parse numbered seqs data\n",
    "    try:\n",
    "        df = pd.read_csv('tmp_align_B.csv')\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError('Error: ANARCI failed to align, please check whether ANARCI exists in your environment')\n",
    "        \n",
    "    cols = ['104', '105', '106', '107', '108', '109', '110', '111', '111A', '111B', '112C', '112B', '112A', '112', '113', '114', '115', '116', '117', '118']\n",
    "    seqs_al = []\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            seqs_al_curr = df[col].values\n",
    "            seqs_al.append(seqs_al_curr)\n",
    "        else:\n",
    "            seqs_al_curr = np.full([len(df)], '-')\n",
    "            seqs_al.append(seqs_al_curr)\n",
    "    seqs_al = [''.join(seq) for seq in np.array(seqs_al).T]\n",
    "    df_al = df[['Id']]\n",
    "    df_al['cdr3_align'] = seqs_al\n",
    "    \n",
    "    ## merge\n",
    "    # os.remove('tmp_align_B.csv')\n",
    "#     os.remove('tmp_faketcr.fasta')\n",
    "    df = df_seqs.merge(df_al, how='inner', on='Id')\n",
    "    df = df.set_index('cdr3')\n",
    "    return df.loc[seqs, 'cdr3_align'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4231516a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class PretrainedEncoder:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.ae_model = load_ae_model(tokenizer)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def encode_pretrained_epi(self, epi_seqs):\n",
    "        enc = self.infer(epi_seqs)\n",
    "        enc_vec = enc[2]\n",
    "        enc_seq = enc[-1]\n",
    "        return enc_seq, enc_vec\n",
    "    \n",
    "    def infer(self, seqs):\n",
    "        # # seqs encoding\n",
    "        n_seqs = len(seqs)\n",
    "        len_seqs = [len(seq) for seq in seqs]\n",
    "        assert (np.max(len_seqs) <= 12) and (np.min(len_seqs)>=8), ValueError('Lengths of epitopes must be within [8, 12]')\n",
    "        encoding = np.zeros([n_seqs, 12], dtype='int32')\n",
    "        for i, seq in enumerate(seqs):\n",
    "            len_seq = len_seqs[i]\n",
    "            if len_seq == 8:\n",
    "                encoding[i, 2:len_seq+2] = self.tokenizer.id_list(seq)\n",
    "            elif (len_seq == 9) or (len_seq == 10):\n",
    "                encoding[i, 1:len_seq+1] = self.tokenizer.id_list(seq)\n",
    "            else:\n",
    "                encoding[i, :len_seq] = self.tokenizer.id_list(seq)\n",
    "        # # pretrained ae features\n",
    "        inputs = torch.from_numpy(encoding)\n",
    "        out, seq_enc, vec, indices = self.ae_model(inputs)\n",
    "        out = np.argmax(out.detach().cpu().numpy(), -1)\n",
    "        return [\n",
    "            out,\n",
    "            seq_enc.detach().cpu().numpy(),\n",
    "            vec.detach().cpu().numpy(),\n",
    "            indices,\n",
    "            encoding\n",
    "        ]\n",
    "class View(nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "    def forward(self, input):\n",
    "        shape = [input.shape[0]] + list(self.shape)\n",
    "        return input.view(*shape)\n",
    "def load_ae_model(tokenizer, path='./epi_ae.ckpt',):\n",
    "    # tokenizer = Tokenizer()\n",
    "    ## load model\n",
    "    model_args = dict(\n",
    "        tokenizer = tokenizer,\n",
    "        dim_hid = 32,\n",
    "        len_seq = 12,\n",
    "    )\n",
    "    model = AutoEncoder(**model_args)\n",
    "    model.eval()\n",
    "\n",
    "    ## load weights\n",
    "    state_dict = torch.load(path, map_location=device)\n",
    "    state_dict = {k[6:]:v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "        tokenizer,\n",
    "        dim_hid,\n",
    "        len_seq,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        embedding = tokenizer.embedding_mat()\n",
    "        vocab_size, dim_emb = embedding.shape\n",
    "        self.embedding_module = nn.Embedding.from_pretrained(torch.FloatTensor(embedding), padding_idx=0, )\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(dim_emb, dim_hid, 3, padding=1),\n",
    "            nn.BatchNorm1d(dim_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(dim_hid, dim_hid, 3, padding=1),\n",
    "            nn.BatchNorm1d(dim_hid),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.seq2vec = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(len_seq * dim_hid, dim_hid),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.vec2seq = nn.Sequential(\n",
    "            nn.Linear(dim_hid, len_seq * dim_hid),\n",
    "            nn.ReLU(),\n",
    "            View(dim_hid, len_seq)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(dim_hid, dim_hid, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(dim_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(dim_hid, dim_hid, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(dim_hid),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.out_layer = nn.Linear(dim_hid, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.long()\n",
    "        seq_emb = self.embedding_module(inputs)\n",
    "        \n",
    "        seq_enc = self.encoder(seq_emb.transpose(1, 2))\n",
    "        vec = self.seq2vec(seq_enc)\n",
    "        seq_repr = self.vec2seq(vec)\n",
    "        indices = None\n",
    "        seq_dec = self.decoder(seq_repr)\n",
    "        out = self.out_layer(seq_dec.transpose(1, 2))\n",
    "        return out, seq_enc, vec, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "031a376f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_with_loader(type_ = 'train',fold = None,  batch_size = 128):\n",
    "    if type_ != 'train' and type_ != 'val':\n",
    "#         data = pd.read_csv('../data/justina_test.csv')\n",
    "#         data = pd.read_csv('./unique_data_IEDB/unique_data_IEDB/随机错配/unique_all_1V1_IEDB.csv')\n",
    "#         data = pd.read_csv('/home/happy/Downloads/NetTCR-2.0-main/data/test/all_Immune_newneg1V1.csv')\n",
    "#         data = pd.read_csv('./绘图用结果/justina_test1v1.csv')\n",
    "        data = pd.read_csv('./extend_testdata/mari_data_100%test.csv')\n",
    "        \n",
    "        \n",
    "    elif type_ == 'train':\n",
    "        data = pd.read_csv('../突变负样本/VDJ_10X_McPAS_1V5/train_VDJ_10X_McPAS_1V5_{}.csv'.format(fold))\n",
    "\n",
    "    elif type_ == 'val':\n",
    "        data = pd.read_csv('../突变负样本/VDJ_10X_McPAS_1V5/eva_VDJ_10X_McPAS_1V5_{}.csv'.format(fold))\n",
    "\n",
    "    pep_inputs, hla_inputs,labels = make_data(data)\n",
    "#     print(labels)\n",
    "    loader = Data.DataLoader(MyDataSet(pep_inputs, hla_inputs,labels), batch_size, shuffle = False, num_workers = 0)\n",
    "    n_samples = len(pep_inputs)\n",
    "    len_cdr3 = len(hla_inputs[0])\n",
    "    len_epi = len(pep_inputs[0])\n",
    "#     print(n_samples,len_cdr3,len_epi)\n",
    "    encoding_mask = np.zeros([n_samples, len_cdr3,len_epi])\n",
    "    for idx_sample, (enc_cdr3_this, enc_epi_this) in enumerate(zip(hla_inputs, pep_inputs)):\n",
    "        mask = np.ones([len_cdr3,len_epi])\n",
    "        zero_cdr3 = (enc_cdr3_this == 0)\n",
    "        mask[zero_cdr3,:] = 0\n",
    "        zero_epi = (enc_epi_this == 0)\n",
    "        mask[:,zero_epi] = 0\n",
    "#         print(mask.shape)\n",
    "        encoding_mask[idx_sample] = mask\n",
    "    return data, pep_inputs, hla_inputs, labels,loader,encoding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21aec6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save fasta file to tmp_faketcr.fasta\n",
      " Aligning...\n",
      "zsh:1: command not found: ANARCI\n",
      "['CASSPD--------RETQYF' 'CASSFV--------NDNQYF' 'CASSLEW------GYANAFF' ...\n",
      " 'CASSRAA------CFAHQYF' 'CSANRAGA-----GSSTQYF' 'CASSWGDWW---VGCCIQYF']\n",
      "[[ 0 17  4 ...  3  0  0]\n",
      " [ 0  0 10 ...  7  0  0]\n",
      " [ 0  5 14 ... 14  0  0]\n",
      " ...\n",
      " [ 0  4 18 ...  1  2  0]\n",
      " [ 0 14  4 ... 16  0  0]\n",
      " [ 0 12  4 ...  3  0  0]]\n",
      "1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-4 ****Test  Epoch-None/150: Loss = 0.765296\n",
      "tn = 920, fp = 40, fn = 80, tp = 112\n",
      "y_pred: 0 = 1000 | 1 = 152\n",
      "y_true: 0 = 960 | 1 = 192\n",
      "auc=0.9577|sensitivity=0.5833|specificity=0.9583|acc=0.8958|mcc=0.5965\n",
      "precision=0.7368|recall=0.5833|f1=0.6512|aupr=0.7985\n",
      "hahha:                   CDR3b     peptide  binder  y_pred        y_prob\n",
      "0          CASSPDRETQYF   CLGGLLTMV       0       0  1.156557e-14\n",
      "1          CASSFVNDNQYF    NEGVKAAW       0       0  7.856281e-08\n",
      "2        CASSLEWGYANAFF   IMNDMPIYM       0       0  1.957392e-09\n",
      "3        CASSDPHGKSHQFF  AVFDRKSDAK       0       0  1.504651e-17\n",
      "4          CASSHRSIQLFF   NLVPMVATV       0       0  1.875631e-10\n",
      "...                 ...         ...     ...     ...           ...\n",
      "1147    CASDIDRGIDQPQHF   KTWGQYWQV       0       0  1.145731e-17\n",
      "1148    CASSFNKKPSETQYF   KLGGALQAK       0       1  9.940882e-01\n",
      "1149     CASSRAACFAHQYF  LPRRSGAAGA       0       0  1.163078e-43\n",
      "1150    CSANRAGAGSSTQYF   MLDLQPETT       0       0  7.346461e-19\n",
      "1151  CASSWGDWWVGCCIQYF   KLSYGIATV       0       0  0.000000e+00\n",
      "\n",
      "[1152 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "path_saver = './new_data_trian_pkl/tcr_st_layer1_multihead5_fold1_netmhcpan.pkl'\n",
    "fold = 4\n",
    "model = Transformer().to(device)\n",
    "model.load_state_dict(torch.load(path_saver))\n",
    "# model_eval = model.eval()\n",
    "type_ = 'test'\n",
    "save_ = False\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# fold = 0\n",
    "ep_best = None\n",
    "dir_head = './shiyan/all_IEDB_newneg1V1.csv_Fold-4.csv'\n",
    "data, pep_inputs, hla_inputs, labels, loader,_ = data_with_loader(type_,fold = fold,  batch_size = batch_size)\n",
    "print(len(data))\n",
    "independent_metrics_res, independent_ys_res, independent_attn_res= eval_step(model, loader, fold, ep_best, epochs,dir_head,use_cuda)\n",
    "#         print(independent_metrics_res[2])\n",
    "data['y_pred'], data['y_prob']= independent_metrics_res[1],independent_metrics_res[2]\n",
    "\n",
    "print(\"hahha:\",data)\n",
    "# data.to_csv('result_unique_newdata_test/all_Immune_newneg1V1.csv',index=False)\n",
    "data.to_csv('./extend_testdata/result_mira.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c81504a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './tcr_st_layer1_multihead5_fold1_netmhcpan.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2189735/4227453451.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# model = STSeqCls((21, 100), num_cls=2, hidden_size=300, num_layers=1, num_head=8, max_len=29,cls_hidden_size=600,dropout=0.1,head_dim=32).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_saver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# model_eval = model.eval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './tcr_st_layer1_multihead5_fold1_netmhcpan.pkl'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "for n_heads in range(5,6):\n",
    "    for fold in range(1,6):\n",
    "\n",
    "        path_saver = './tcr_st_layer1_multihead{}_fold{}_netmhcpan.pkl'.format(n_heads,fold)\n",
    "#         path_saver = './tcr_st_layer1_multihead{}_fold{}_netmhcpan.pkl'.format(n_heads,fold)\n",
    "# model = STSeqCls((21, 100), num_cls=2, hidden_size=300, num_layers=1, num_head=8, max_len=29,cls_hidden_size=600,dropout=0.1,head_dim=32).to(device)\n",
    "        model = Transformer().to(device)\n",
    "        model.load_state_dict(torch.load(path_saver))\n",
    "# model_eval = model.eval()\n",
    "        type_ = 'test'\n",
    "        save_ = False\n",
    "        use_cuda = True\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        # fold = 0\n",
    "        ep_best = None\n",
    "        print(\"n_head is:\"+str(n_heads))\n",
    "        dir_head = './shiyan/justina_1V5_head_{}'.format(n_heads)\n",
    "        data, pep_inputs, hla_inputs, labels, loader,_ = data_with_loader(type_,fold = fold,  batch_size = batch_size)\n",
    "        print(len(data))\n",
    "        independent_metrics_res, independent_ys_res, independent_attn_res= eval_step(model, loader, fold, ep_best, epochs,dir_head,use_cuda)\n",
    "#         print(independent_metrics_res[2])\n",
    "        data['y_pred'], data['y_prob']= independent_metrics_res[1],independent_metrics_res[2]\n",
    "        \n",
    "        print(data)\n",
    "        data.to_csv('tmp_{}.csv'.format(fold),index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5142d671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44ce58a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn = 337, fp = 39, fn = 62, tp = 314\n",
      "y_pred: 0 = 399 | 1 = 353\n",
      "y_true: 0 = 376 | 1 = 376\n",
      "auc=0.9507|sensitivity=0.8351|specificity=0.8963|acc=0.8657|mcc=0.7328\n",
      "precision=0.8895|recall=0.8351|f1=0.8615|aupr=0.9368\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 读取五个文件\n",
    "files = ['tmp_1.csv', 'tmp_2.csv', 'tmp_3.csv', 'tmp_4.csv', 'tmp_5.csv']\n",
    "\n",
    "# 创建一个空的 DataFrame 用于存储平均值\n",
    "average_df = pd.DataFrame()\n",
    "\n",
    "# 循环遍历每个文件\n",
    "for file in files:\n",
    "    # 读取文件\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # 将 'y_pred' 和 'y_prob' 列相加\n",
    "    if average_df.empty:\n",
    "        average_df = df[['y_pred', 'y_prob']]\n",
    "    else:\n",
    "        average_df[['y_pred', 'y_prob']] += df[['y_pred', 'y_prob']]\n",
    "\n",
    "# 计算平均值\n",
    "average_df[['y_pred', 'y_prob']] /= len(files)\n",
    "\n",
    "# 将其他列保持不变\n",
    "other_columns = df.drop(columns=['y_pred', 'y_prob'])\n",
    "\n",
    "# 将结果保存为 'justia.csv' 文件\n",
    "result_df = pd.concat([other_columns, average_df], axis=1)\n",
    "result_df.to_csv('result_10Xneg_IEDB.csv', index=False)\n",
    "dir_head = './shiyan/A_1V5_average'\n",
    "# 将 'y_true' 和 'y_pred' 转换为列表，确保它们是二进制的\n",
    "y_true_list = result_df['label']\n",
    "y_pred_list = result_df['y_pred'].astype(int)\n",
    "\n",
    "# 'y_prob' 可以保持不变，因为它是连续型的概率值\n",
    "y_prob_list = list(result_df['y_prob'])\n",
    "\n",
    "# 调用 performances 函数\n",
    "metrics_val = performances(y_true_list, y_pred_list, y_prob_list, dir_head, True)\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    # 读取文件\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb30f463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a455cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620b0489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TranTCR",
   "language": "python",
   "name": "trantcr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
